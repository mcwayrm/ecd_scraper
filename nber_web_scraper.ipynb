{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web-Scraping Project\n",
    "\n",
    "### Preparing for Web-Scraping on NBER.\n",
    "\n",
    "https://admin.nber.org/xsearch?q=early+childhood+development+OR+Education&whichsearch=ftpub&restrict_papers=yes&fullresults=1&datefilter=&b=search+again \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "\n",
    "# !pip install BeautifulSoup4 as bs4\n",
    "# !pip install pandas\n",
    "# !pip install splinter\n",
    "\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates empty lists for each variable\n",
    "report_title = []\n",
    "report_summary = []\n",
    "report_citation = []\n",
    "report_link = []\n",
    "report_publish_date = []\n",
    "report_author = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': './chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://admin.nber.org/custom?q=early+childhood+development&restrict_papers=yes&client=test3_fe&proxystylesheet=test3_fe&site=default_collection&entqr=0&ud=1&output=xml_no_dtd&oe=UTF-8&ie=UTF-8&btnG=Search'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whattywhat\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://admin.nber.org/custom?q=early+childhood+development&restrict_papers=yes&client=test3_fe&proxystylesheet=test3_fe&site=default_collection&entqr=0&ud=1&output=xml_no_dtd&oe=UTF-8&ie=UTF-8&btnG=Search\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "for j in range(0,10):\n",
    "\n",
    "    # Using Google Chrome drive open test explorer\n",
    "    html_list.append(browser.html)\n",
    "    reports_soup = BeautifulSoup(html_list[i], 'html.parser')\n",
    "\n",
    "    # Creates a list of the current result page\n",
    "    reports_list = reports_soup.find_all('li', class_='searchResult')\n",
    "    for i in range(0, len(reports_list)):\n",
    "        try:\n",
    "\n",
    "            title = reports_list[i].find('a', class_='resultTitle').get_text()\n",
    "            summary = reports_list[i].find('div', class_='searchResultAbstract').get_text()\n",
    "            link = \"https://www.nber.org\" + reports_list[i].find('p', class_='url').get_text()\n",
    "            publish_date = reports_list[i].find('span', class_='searchResultNiceDate').get_text()\n",
    "            author = reports_list[i].find('span', class_='searchResultAuthor').get_text()\n",
    "\n",
    "            report_title.append(title)\n",
    "            report_summary.append(summary)\n",
    "            report_link.append(link)\n",
    "            report_publish_date.append(publish_date)\n",
    "            report_author.append(author)\n",
    "\n",
    "            # Stop the loop for 2 seconds to make sure catching the popup window\n",
    "            time.sleep(random.uniform(0,2))\n",
    "\n",
    "        except AttributeError as e:\n",
    "            print(e)\n",
    "\n",
    "        browser.click_link_by_text('More results.')\n",
    "        time.sleep(random.randint(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the variables into a dataframe\n",
    "data_df = pd.DataFrame(list(zip(report_title, report_summary, report_link, report_publish_date, report_author)), \n",
    "                       columns=[\"title\", \"summary\", \"link\", \"publish_date\", \"author\"])\n",
    "\n",
    "# Saving the dataframe into CSV\n",
    "data_df.to_csv(\"data.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
